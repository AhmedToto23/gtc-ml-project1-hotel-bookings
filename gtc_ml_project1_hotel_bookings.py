# -*- coding: utf-8 -*-
"""gtc-ml-project1-hotel-bookings

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OAzlGO-idBS9Mxnu22lh-J4NzYZOkA1X

Load Data
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('hotel_bookings.csv')

"""EDA"""

print("Dataset shape: ",df.shape)

# Info
df.info()

df.head(5)

# Describtion of the numerical columns
df.describe()

# Describtion of all columns
df.describe(include='all')

"""Missing and duplicated values"""

# number of null values per column
df.isnull().sum()

# Missing percentage per column
missing = df.isnull().sum().sort_values(ascending=False)
missing_percentage = (missing / len(df) * 100).round(2)
missing_percentage

# Number of duplicated data per column
for i in df.columns:
  print(i,"=>",df[i].duplicated().sum())

"""Data Quality Report"""

def build_column_stats(series: pd.Series) -> dict:

    total = len(series)

    dt = str(series.dtype)
    non_null_cnt = series.count()
    missing_cnt = series.isnull().sum()
    missing_pct = (missing_cnt / total * 100).round(2)
    uniq_cnt = series.nunique(dropna=True)

    if series.dropna().empty:
        top = None
    else:
        top = series.dropna().value_counts().idxmax()

    return {
        "dtype": dt,
        "non_null": int(non_null_cnt),
        "missing": int(missing_cnt),
        "missing_pct": float(missing_pct),
        "unique": int(uniq_cnt),
        "top_value": top
    }

def data_quality_report_alt(df: pd.DataFrame) -> pd.DataFrame:
    stats_list = []
    total_rows = len(df)

    for name, ser in df.items():
        col_stats = build_column_stats(ser)
        row = {
            "column": name,
            "dtype": col_stats["dtype"],
            "non_null": col_stats["non_null"],
            "missing": col_stats["missing"],
            "missing_pct": col_stats["missing_pct"],
            "unique": col_stats["unique"],
            "top_value": col_stats["top_value"],
        }
        stats_list.append(row)

    report_df = pd.DataFrame(stats_list)
    report_df = report_df.sort_values(by="column").reset_index(drop=True)
    return report_df

report = data_quality_report_alt(df)
report.to_csv('data_quality_report.csv', index=False)
print("Saved data_quality_report.csv")
report

#Issues printer
import pandas as pd
from typing import List, Optional

def collect_issues_from_quality(quality_df: pd.DataFrame, orig_df: pd.DataFrame) -> List[str]:
    issues_list: List[str] = []
    total_rows = len(orig_df)

    miss_thresh = 30.0
    highly_missing = quality_df.loc[quality_df['missing_pct'] > miss_thresh, 'column'].tolist()
    if highly_missing:
        issues_list.append(f"Columns with >{miss_thresh}% missing: {highly_missing}")


    card_thresh = total_rows * 0.5
    high_card_cols = quality_df.loc[quality_df['unique'] > card_thresh, 'column'].tolist()
    if high_card_cols:
        issues_list.append(
            f"Columns with very high cardinality (>50% rows unique): {high_card_cols}"
        )


    if issues_list:
        print("Quick issues detected:")
        for item in issues_list:
            print("-", item)
    else:
        print("No obvious automatic flags. (data_quality_report.csv).")

    return issues_list

dq = data_quality_report_alt(df)
issues = collect_issues_from_quality(dq, df)

"""Data Visualization"""

import seaborn as sns
import matplotlib.pyplot as plt
palette=sns.color_palette("husl",len(df.select_dtypes(include="number").columns))
for idx,col in enumerate (df.select_dtypes(include="number").columns):
  plt.figure(figsize=(8,4))
  sns.histplot(data=df,x=col,color=palette[idx],edgecolor="black",kde=True)
  plt.title(f"Distribution of {col}",fontsize=14,fontweight="bold")
  plt.grid()
  plt.show()

plt.figure(figsize=(12,6))
sns.heatmap(df.isnull(), cbar=False)
plt.title('Missing values heatmap')
plt.show()

# Check the outliers
for col in df.select_dtypes(include="number"):
  plt.figure(figsize=(10,3))
  sns.boxplot(data=df,x=df[col],palette="Set2")
  plt.title(f"Boxplot of {col}",fontsize=14)
  plt.show()

  plt.figure(figsize=(10,3))
  sns.histplot(df[col].dropna(), bins=50)
  plt.title(f'Histogram of {col}')
  plt.show()

"""Data Cleaning"""

df_copy = df.copy()

# Impute missing values with the mean for each numerical column
for col in df_copy.select_dtypes(include="number").columns:
    df_copy[col].fillna(df_copy[col].mean(), inplace=True)
df_copy.isnull().sum()

# Impute missing values with the mode for country column
df_copy["country"] = df_copy["country"].fillna(df_copy['country'].mode()[0],inplace=True)
df_copy.isnull().sum()

# Removing the duplcated columns
df_copy = df_copy.drop_duplicates()
df_copy.duplicated().sum()

df_copy.dtypes.head(32)

print("Correcting data type")
df_copy['reservation_status_date'] = pd.to_datetime(df_copy['reservation_status_date'],errors='coerce')
df_copy['children'] = df_copy['children'].astype('i')
print(df_copy[['reservation_status_date','children']].dtypes)

outliers_col=[]
for col in df_copy.select_dtypes(include="number").columns:
  q1 = df_copy[col].quantile(0.25)
  q3 = df_copy[col].quantile(0.75)
  iqr = q3 - q1
  lower_bound = q1 - 1.5 * iqr
  upper_bound = q3 + 1.5 * iqr
  count_outliers = df_copy[(df_copy[col] < lower_bound) | (df_copy[col] > upper_bound)].shape[0]
  if count_outliers > 0:
      outliers_col.append(col)

# Columns which have outliers
outliers_col

#Handling the outhliers
def outliers_handling(df_copy: pd.DataFrame, cols: list[str]) -> None:
    for col in cols:
        s = df_copy[col]
        if not pd.api.types.is_numeric_dtype(s):
            continue

        q1 = s.quantile(0.25)
        q3 = s.quantile(0.75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        df_copy.loc[df_copy[col] < lower_bound, col] = lower_bound
        df_copy.loc[df_copy[col] > upper_bound, col] = upper_bound

outliers_handling(df_copy, cols=outliers_col)

# Check the outliers again
for col in outliers_col:
  plt.figure(figsize=(10,3))
  sns.boxplot(data=df_copy,x=df_copy[col],palette="Set2")
  plt.title(f"Boxplot of {col}",fontsize=14)
  plt.show()

"""Feature Engineering"""

df_fet=df_copy.copy()
# total_guests = adults + children + babies
df_fet['total_guests'] = df_fet['adults'] + df_fet['children'].fillna(0) + df_fet['babies']

# total_nights = stays_in_weekend_nights + stays_in_week_nights
df_fet['total_nights'] = df_fet['stays_in_weekend_nights'] + df_fet['stays_in_week_nights']

# is_family
df_fet['is_family'] = np.where((df_fet['children'] + df_fet['babies']) > 0, 1, 0)
df_fet['is_family'].unique()

df_fet.dtypes

#Encode Categorical Variables
from sklearn.preprocessing import OneHotEncoder
df_copy = pd.get_dummies(df_copy, columns=['meal', 'market_segment'], drop_first=True)
country_freq = df['country'].value_counts(normalize=True)
df_copy['country_encoded'] = df_copy['country'].map(country_freq)
rare_countries = country_freq[country_freq < 0.01].index
df_copy['country_grouped'] = df_copy['country'].replace(rare_countries, 'Other')

#Remove leakage
df_copy = df_copy.drop(['reservation_status', 'reservation_status_date'], axis=1)

# Final Preparation : Split cleaned dataset into training and testing sets
from sklearn.model_selection import train_test_split

X = df.drop('is_canceled', axis=1)
y = df['is_canceled']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

X_train.to_csv("X_train.csv", index=False)
X_test.to_csv("X_test.csv", index=False)
y_train.to_csv("y_train.csv", index=False)
y_test.to_csv("y_test.csv", index=False)
print("All datasets saved!")